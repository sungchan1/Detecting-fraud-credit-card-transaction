{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_fraud.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungchan1/goingSaboho/blob/gwangseok/credit_fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgPSBObxenCF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSrRpPDp98Kx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Credit_fraud/data/creditcard.csv')\n",
        "std_scaler = StandardScaler()\n",
        "rob_scaler = RobustScaler()\n",
        "\n",
        "\n",
        "df['Time'] = std_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "df['Amount'] = std_scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPxfF96LrBBL"
      },
      "source": [
        "# data distribution 시각화\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "row_cnt = len(df)\n",
        "zero_cnt = df['Class'].value_counts()[0]\n",
        "one_cnt = df['Class'].value_counts()[1]\n",
        "ratio_no_fraud = round(zero_cnt/row_cnt * 100,2)\n",
        "ratio_fraud = round(one_cnt/row_cnt * 100,2)\n",
        "\n",
        "\n",
        "colors = [\"#0101DF\", \"#DF0101\"]\n",
        "sns.countplot('Class', data=df, palette=colors)\n",
        "plt.title(f'Class Distributions \\n (0: No Fraud ({zero_cnt}, {ratio_no_fraud} %) '\n",
        "          f'\\n (1: Fraud ({one_cnt}, {ratio_fraud} %))', fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNZFF6eqN3-M"
      },
      "source": [
        "# Data Correlation Matrices\n",
        "\n",
        "# pandas corr를 통해 피어슨 상관계수 사용\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(24,10))\n",
        "ax=sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20})\n",
        "ax.set_title(\"Correlation Matrix\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnpvC8vxvWvS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
        "\n",
        "# UnderSampling 하기 전에 original dataframe을 test와 train으로 나눈다.\n",
        "# Under 혹은 OverSampling 이후 원래 데이터로 검증하기 위해서이다.\n",
        "\n",
        "X = df.drop('Class',axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# random_state : 난수 값을 지정하면 여러번 다시 수행해도 동일한 결과가 나오게 해줌\n",
        "# shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지 결정\n",
        "# test : train = 4 : 1\n",
        "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
        "\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "# 배열로 바꾸기\n",
        "# original_Xtrain = original_Xtrain.values\n",
        "# original_Xtest = original_Xtest.values\n",
        "# original_ytrain = original_ytrain.values\n",
        "# original_ytest = original_ytest.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWANksx4KtES"
      },
      "source": [
        "# UnderSampling : NearMiss algorithm\n",
        "\n",
        "# dataframe.sample(frac=1) : data를 뽑기전 random하게 섞기\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# fraud의 수가 492개 이므로 492개의 non_fraud를 가져온다.\n",
        "fraud_df = df.loc[df['Class'] == 1]\n",
        "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
        "\n",
        "# pd.concat: data frame 합치기\n",
        "undersampling_df = pd.concat([fraud_df, non_fraud_df]).sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTSGOD0uNh6g"
      },
      "source": [
        "# undersampling data distribution 시각화\n",
        "\n",
        "u_zero_cnt = undersampling_df['Class'].value_counts()[0]\n",
        "u_one_cnt = undersampling_df['Class'].value_counts()[1]\n",
        "sns.countplot('Class', data=undersampling_df, palette=colors)\n",
        "plt.title(f'Equally Distributed Classes \\n (0: No Fraud ({u_zero_cnt})'\n",
        "            f'\\n (1: Fraud ({u_one_cnt})', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd_N04uUPXy4"
      },
      "source": [
        "# undersampling data correlation\n",
        "# pandas corr를 통해 피어슨 상관계수 사용\n",
        "plt.figure(figsize=(24,10))\n",
        "\n",
        "sub_sample_corr = undersampling_df.corr()\n",
        "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20})\n",
        "ax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\n",
        "plt.show()\n",
        "# heatmap의 class를 보자.\n",
        "# V3, V10, V12, V14은 음의 상관계수를 가진다. 즉, 이 값들이 작을수록 fraud인 것이다.\n",
        "# 반대로 V2, V4, V11는 양의 상관계수를 가진다. 즉, 이 값들이 클수록 fraud인 것이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YBXwpkrZ2ud"
      },
      "source": [
        "# v3, v10, v12, v14 outlier 확인하기\n",
        "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
        "\n",
        "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
        "sns.boxplot(x=\"Class\", y=\"V3\", data=undersampling_df, palette=colors, ax=axes[0])\n",
        "axes[0].set_title('V3 vs Class Negative Correlation')\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V10\", data=undersampling_df, palette=colors, ax=axes[1])\n",
        "axes[1].set_title('V10 vs Class Negative Correlation')\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V12\", data=undersampling_df, palette=colors, ax=axes[2])\n",
        "axes[2].set_title('V12 vs Class Negative Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V14\", data=undersampling_df, palette=colors, ax=axes[3])\n",
        "axes[3].set_title('V14 vs Class Negative Correlation')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAy4hFi7adDb"
      },
      "source": [
        "# v2, v4, v11 outlier 확인하기\n",
        "f, axes = plt.subplots(ncols=3, figsize=(20,4))\n",
        "\n",
        "# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n",
        "sns.boxplot(x=\"Class\", y=\"V2\", data=undersampling_df, palette=colors, ax=axes[0])\n",
        "axes[0].set_title('V2 vs Class Positive Correlation')\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V4\", data=undersampling_df, palette=colors, ax=axes[1])\n",
        "axes[1].set_title('V4 vs Class Positive Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V11\", data=undersampling_df, palette=colors, ax=axes[2])\n",
        "axes[2].set_title('V11 vs Class Positive Correlation')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF9IIpkRUZ7s"
      },
      "source": [
        "# V3, V10, V12, V14 data의 분포와 정규분포\n",
        "# V14만 정규분포 형태를 띄고 있다.\n",
        "from scipy.stats import norm\n",
        "\n",
        "f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20, 6))\n",
        "\n",
        "v3_fraud_dist = undersampling_df['V3'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v3_fraud_dist,ax=ax4, fit=norm, color='#C5B3F9')\n",
        "ax1.set_title('V3 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v10_fraud_dist = undersampling_df['V10'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v10_fraud_dist,ax=ax1, fit=norm, color='#C5B3F9')\n",
        "ax2.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v12_fraud_dist = undersampling_df['V12'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
        "ax3.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v14_fraud_dist = undersampling_df['V14'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v14_fraud_dist,ax=ax3, fit=norm, color='#FB8861')\n",
        "ax4.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuWXBvk1bYtz"
      },
      "source": [
        "# V2, V4, V11, V19 data의 분포와 정규분포\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n",
        "\n",
        "v2_fraud_dist = undersampling_df['V2'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v2_fraud_dist,ax=ax1, fit=norm, color='#C5B3F9')\n",
        "ax1.set_title('V2 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v4_fraud_dist = undersampling_df['V4'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v4_fraud_dist,ax=ax3, fit=norm, color='#FB8861')\n",
        "ax3.set_title('V4 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v11_fraud_dist = undersampling_df['V11'].loc[undersampling_df['Class'] == 1].values\n",
        "sns.distplot(v11_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
        "ax2.set_title('V11 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HItmU8hkXGLa"
      },
      "source": [
        "# Anomaly Detection: remove \"extreme outliers\"\n",
        "# Interquartile Range 방법을 사용해 25% 아래이거나 75% 위에 있는 data를 제거한다.\n",
        "\n",
        "# V2 outliers 제거\n",
        "v2_fraud = undersampling_df['V2']\n",
        "q25, q75 = np.percentile(v2_fraud, 25), np.percentile(v2_fraud, 75)\n",
        "v2_iqr = q75 - q25\n",
        "v2_cut_off = v2_iqr * 1.5\n",
        "v2_lower, v2_upper = q25 - v2_cut_off, q75 + v2_cut_off\n",
        "outliers = [x for x in v2_fraud if x < v2_lower or x > v2_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V2'] > v2_upper) | (undersampling_df['V2'] < v2_lower)].index)\n",
        "\n",
        "# v11 outliers 제거\n",
        "v11_fraud = undersampling_df['V11']\n",
        "q25, q75 = np.percentile(v11_fraud, 25), np.percentile(v11_fraud, 75)\n",
        "v11_iqr = q75 - q25\n",
        "v11_cut_off = v11_iqr * 1.5\n",
        "v11_lower, v11_upper = q25 - v11_cut_off, q75 + v11_cut_off\n",
        "outliers = [x for x in v11_fraud if x < v11_lower or x > v11_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V11'] > v11_upper) | (undersampling_df['V11'] < v11_lower)].index)\n",
        "\n",
        "# V3 outliers 제거\n",
        "v3_fraud = undersampling_df['V3']\n",
        "q25, q75 = np.percentile(v3_fraud, 25), np.percentile(v3_fraud, 75)\n",
        "v3_iqr = q75 - q25\n",
        "v3_cut_off = v3_iqr * 1.5\n",
        "v3_lower, v3_upper = q25 - v3_cut_off, q75 + v3_cut_off\n",
        "outliers = [x for x in v3_fraud if x < v3_lower or x > v3_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V3'] > v3_upper) | (undersampling_df['V3'] < v3_lower)].index)\n",
        "\n",
        "# V10 outliers 제거\n",
        "v10_fraud = undersampling_df['V10']\n",
        "q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\n",
        "v10_iqr = q75 - q25\n",
        "v10_cut_off = v10_iqr * 1.5\n",
        "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
        "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V10'] > v10_upper) | (undersampling_df['V10'] < v10_lower)].index)\n",
        "\n",
        "# V12 outliers 제거\n",
        "v12_fraud = undersampling_df['V12'].loc[undersampling_df['Class'] == 1].values\n",
        "q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\n",
        "v12_iqr = q75 - q25\n",
        "v12_cut_off = v12_iqr * 1.5\n",
        "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
        "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V12'] > v12_upper) | (undersampling_df['V12'] < v12_lower)].index)\n",
        "\n",
        "# v14 outliers 제거\n",
        "v14_fraud = undersampling_df['V14'].loc[undersampling_df['Class'] == 1].values\n",
        "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
        "v14_iqr = q75 - q25\n",
        "v14_cut_off = v14_iqr * 1.5\n",
        "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
        "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
        "undersampling_df = undersampling_df.drop(undersampling_df[(undersampling_df['V14'] > v14_upper) | (undersampling_df['V14'] < v14_lower)].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWxyxhiZdXlL"
      },
      "source": [
        "f,(ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,8))\n",
        "\n",
        "# Feature V3\n",
        "sns.boxplot(x=\"Class\", y=\"V3\", data=undersampling_df, ax=ax1, palette=colors)\n",
        "ax1.set_title(\"V3 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "# Feature V10\n",
        "sns.boxplot(x=\"Class\", y=\"V10\", data=undersampling_df, ax=ax2, palette=colors)\n",
        "ax2.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "# Feature V12\n",
        "sns.boxplot(x=\"Class\", y=\"V12\", data=undersampling_df, ax=ax3, palette=colors)\n",
        "ax3.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "# Feature V14\n",
        "sns.boxplot(x=\"Class\", y=\"V14\", data=undersampling_df,ax=ax4, palette=colors)\n",
        "ax4.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDJHhaUg7wmJ"
      },
      "source": [
        "f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,8))\n",
        "# Feature V2\n",
        "sns.boxplot(x=\"Class\", y=\"V2\", data=undersampling_df,ax=ax1, palette=colors)\n",
        "ax1.set_title(\"V2 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "# Feature V11\n",
        "sns.boxplot(x=\"Class\", y=\"V11\", data=undersampling_df,ax=ax2, palette=colors)\n",
        "ax2.set_title(\"V11 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "\n",
        "# Feature V19\n",
        "sns.boxplot(x=\"Class\", y=\"V19\", data=undersampling_df,ax=ax3, palette=colors)\n",
        "ax3.set_title(\"V19 Feature \\n Reduction of outliers\", fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZj4---1cUP_"
      },
      "source": [
        "# 차원 줄이기: t-sne, pca, truncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "x = undersampling_df.drop('Class', axis=1)\n",
        "y = undersampling_df['Class']\n",
        "\n",
        "# x_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(x.values)\n",
        "x_reduced_pca = PCA(n_components=10, random_state=42).fit_transform(x.values)\n",
        "# x_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(x.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2_d0swnh690"
      },
      "source": [
        "# 시각화\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
        "# labels = ['No Fraud', 'Fraud']\n",
        "f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
        "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
        "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
        "\n",
        "# t-sne\n",
        "# ax1.scatter(x_reduced_tsne[:,0], x_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "# ax1.scatter(x_reduced_tsne[:,0], x_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "# ax1.set_title('t-SNE', fontsize=14)\n",
        "# ax1.grid(True)\n",
        "# ax1.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "# pca\n",
        "ax2.scatter(x_reduced_pca[:,0], x_reduced_pca[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "ax2.scatter(x_reduced_pca[:,0], x_reduced_pca[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "ax2.set_title('PCA', fontsize=14)\n",
        "ax2.grid(True)\n",
        "ax2.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "# truncatedSVD\n",
        "# ax3.scatter(x_reduced_svd[:,0], x_reduced_svd[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "# ax3.scatter(x_reduced_svd[:,0], x_reduced_svd[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "# ax3.set_title('Truncated SVD', fontsize=14)\n",
        "# ax3.grid(True)\n",
        "# ax3.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDmSEdb7jGMq"
      },
      "source": [
        "# Undersampling KNN, not dimensional reduction\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "best_parameter = 0\n",
        "best_recall_score = 0\n",
        "lowest_FN = 1\n",
        "lowest_FN_parameter = 0\n",
        "\n",
        "def cal_FN(arr1, arr2):\n",
        "    arr1 = arr1.values\n",
        "    size = len(arr1)\n",
        "    cnt = 0\n",
        "    for i in range(size):\n",
        "        if arr1[i] == 1 and arr2[i] == 0:\n",
        "            cnt += 1\n",
        "\n",
        "    return cnt / size\n",
        "\n",
        "\n",
        "for i in range(1,20):\n",
        "    clf = KNeighborsClassifier(n_neighbors=i)\n",
        "    x = undersampling_df.drop('Class', axis=1)\n",
        "    y = undersampling_df['Class']\n",
        "\n",
        "    # test_size: test 데이터 셋 비율, default = 0.25, random_state : 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값 (int나 RandomState로 입력)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    tmp_FN = cal_FN(y_test, y_pred)\n",
        "\n",
        "    if lowest_FN > tmp_FN:\n",
        "        lowest_FN = tmp_FN\n",
        "        lowest_FN_parameter = i\n",
        "\n",
        "    tmp_recall_score = recall_score(y_test, y_pred)\n",
        "    if best_recall_score < tmp_recall_score:\n",
        "        best_parameter = i\n",
        "        best_recall_score = tmp_recall_score\n",
        "\n",
        "\n",
        "print(lowest_FN_parameter, lowest_FN)\n",
        "print(best_parameter, best_recall_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BETaZpC8k_3k"
      },
      "source": [
        "# Recall : TP/TP+FN\n",
        "# Precision = TP/TP+FP\n",
        "# Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "# F1 score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "y_pred = clf.predict(original_Xtest)\n",
        "\n",
        "print('Recall Score: {:.4f}'.format(recall_score(original_ytest, y_pred)))\n",
        "print('Precision Score: {:.4f}'.format(precision_score(original_ytest, y_pred)))\n",
        "print('F1 Score: {:.4f}'.format(f1_score(original_ytest, y_pred)))\n",
        "print('Accuracy Score: {:.4f}'.format(accuracy_score(original_ytest, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "def5rgLC6ghH"
      },
      "source": [
        "# cross validation으로 점수 확인\n",
        "\n",
        "# precision, recall and F1\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
        "\n",
        "recall = cross_val_score(classifier, X_train, y_train, cv=5, scoring='recall')\n",
        "print('Recall', np.mean(recall), recall)\n",
        "precision = cross_val_score(classifier, X_train, y_train, cv=5, scoring='precision')\n",
        "print('Precision', np.mean(precision), precision)\n",
        "f1 = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
        "print('F1', np.mean(f1), f1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}